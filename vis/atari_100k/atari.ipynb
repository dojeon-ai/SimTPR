{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782db35f-c26d-41f9-b479-98b4ece74ecf",
   "metadata": {},
   "source": [
    "!pip3 install git+https://github.com/google-research/rliable\n",
    "!pip3 install inflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab515d-2004-42c0-8c43-9aac6591ccfd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c94819-cca8-43b8-8199-66645d7a5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9f315b-cadc-4ef8-ab0d-be70cf6282b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import copy\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "\n",
    "import itertools as it\n",
    "import random\n",
    "import inspect\n",
    "import scipy.stats\n",
    " \n",
    "import getpass\n",
    "import os.path as osp\n",
    " \n",
    "# See warnings only once\n",
    "import warnings\n",
    "warnings.filterwarnings('default')\n",
    " \n",
    "import inflection\n",
    "from functools import partial\n",
    "\n",
    "# The answer to life, universe and everything\n",
    "RAND_STATE = np.random.RandomState(42)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee5ce6-104e-4b44-9352-94fec62a1321",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6a232e-2ad3-435d-944e-72b1c73c9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Plotting: Seaborn style and matplotlib params\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Matplotlib params\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "rcParams['legend.loc'] = 'best'\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0526df85-f972-4709-9d2a-e48e3e892c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Plotting Helpers\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    file_name = '{}.pdf'.format(name)\n",
    "    fig.savefig(file_name, format='pdf', bbox_inches='tight')\n",
    "    return file_name\n",
    "\n",
    "def set_axes(ax, xlim, ylim, xlabel, ylabel):\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xlabel(xlabel, labelpad=14)\n",
    "    ax.set_ylabel(ylabel, labelpad=14)\n",
    "\n",
    "def set_ticks(ax, xticks, xticklabels, yticks, yticklabels):\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(yticklabels)\n",
    "\n",
    "def decorate_axis(ax, wrect=10, hrect=10, labelsize='large'):\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    # Deal with ticks and the blank space at the origin\n",
    "    ax.tick_params(length=0.1, width=0.1, labelsize=labelsize)\n",
    "    # Pablos' comment\n",
    "    ax.spines['left'].set_position(('outward', hrect))\n",
    "    ax.spines['bottom'].set_position(('outward', wrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489fc84-8839-43d3-b555-eaa736fb349e",
   "metadata": {},
   "source": [
    "### Score Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5cf9c2-f234-4363-9af1-e48ae11d921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helpers for normalizing scores and plotting histogram plots.\n",
    "\n",
    "\n",
    "def pgs(f):\n",
    "    print(inspect.getsource(f))\n",
    "\n",
    "def score_normalization(res_dict, min_scores, max_scores):\n",
    "    games = res_dict.keys()\n",
    "    norm_scores = {}\n",
    "    for game, scores in res_dict.items():\n",
    "        norm_scores[game] = (scores - min_scores[game])/(max_scores[game] - min_scores[game])\n",
    "    return norm_scores\n",
    "\n",
    "def plot_score_hist(score_matrix, bins=20, figsize=(28, 14), \n",
    "                    fontsize='xx-large', N=6, extra_row=1,\n",
    "                    names=None):\n",
    "    num_tasks = score_matrix.shape[1]\n",
    "    if names is None:\n",
    "        names = ATARI_100K_GAMES\n",
    "    N1 = (num_tasks // N) + extra_row\n",
    "    fig, ax = plt.subplots(nrows=N1, ncols=N, figsize=figsize)\n",
    "    for i in range(N):\n",
    "        for j in range(N1):\n",
    "            idx = j * N + i\n",
    "            if idx < num_tasks:\n",
    "                ax[j, i].set_title(names[idx], fontsize=fontsize)\n",
    "                sns.histplot(score_matrix[:, idx], bins=bins, ax=ax[j,i], kde=True)\n",
    "            else:\n",
    "                ax[j, i].axis('off')\n",
    "            decorate_axis(ax[j, i], wrect=5, hrect=5, labelsize='xx-large')\n",
    "            ax[j, i].xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "            if idx % N == 0:\n",
    "                ax[j, i].set_ylabel('Count', size=fontsize)\n",
    "            else:\n",
    "                ax[j, i].yaxis.label.set_visible(False)\n",
    "            ax[j, i].grid(axis='y', alpha=0.1)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56c791-5f03-4055-a5b5-fb5f39880b96",
   "metadata": {},
   "source": [
    "### Metric Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623eb513-a7a6-4a14-8f56-9224a294ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Stratified Bootstrap CIs and Aggregate metrics\n",
    "\n",
    "StratifiedBootstrap = rly.StratifiedBootstrap\n",
    "\n",
    "IQM = lambda x: metrics.aggregate_iqm(x) # Interquartile Mean\n",
    "OG = lambda x: metrics.aggregate_optimality_gap(x, 1.0) # Optimality Gap\n",
    "MEAN = lambda x: metrics.aggregate_mean(x)\n",
    "MEDIAN = lambda x: metrics.aggregate_median(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ccedd-ff0d-44f5-ac28-a3e07c3c071d",
   "metadata": {},
   "source": [
    "### ATARI 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324e3aec-1113-4da6-8a1e-d5bea08db331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Atari 100k -- List of 26 Games\n",
    "\n",
    "ATARI_100K_GAMES = [\n",
    "    'Alien', 'Amidar', 'Assault', 'Asterix', 'BankHeist', 'BattleZone',\n",
    "    'Boxing', 'Breakout', 'ChopperCommand', 'CrazyClimber', 'DemonAttack',\n",
    "    'Freeway', 'Frostbite', 'Gopher', 'Hero', 'Jamesbond', 'Kangaroo',\n",
    "    'Krull', 'KungFuMaster', 'MsPacman', 'Pong', 'PrivateEye', 'Qbert',\n",
    "    'RoadRunner', 'Seaquest', 'UpNDown'\n",
    "]\n",
    "\n",
    "#@title Score data for Human and random agent\n",
    "\n",
    "\n",
    "RANDOM_SCORES = {\n",
    "    'Alien': 227.8,\n",
    "    'Amidar': 5.8,\n",
    "    'Assault': 222.4,\n",
    "    'Asterix': 210.0,\n",
    "    'BankHeist': 14.2,\n",
    "    'BattleZone': 2360.0,\n",
    "    'Boxing': 0.1,\n",
    "    'Breakout': 1.7,\n",
    "    'ChopperCommand': 811.0,\n",
    "    'CrazyClimber': 10780.5,\n",
    "    'DemonAttack': 152.1,\n",
    "    'Freeway': 0.0,\n",
    "    'Frostbite': 65.2,\n",
    "    'Gopher': 257.6,\n",
    "    'Hero': 1027.0,\n",
    "    'Jamesbond': 29.0,\n",
    "    'Kangaroo': 52.0,\n",
    "    'Krull': 1598.0,\n",
    "    'KungFuMaster': 258.5,\n",
    "    'MsPacman': 307.3,\n",
    "    'Pong': -20.7,\n",
    "    'PrivateEye': 24.9,\n",
    "    'Qbert': 163.9,\n",
    "    'RoadRunner': 11.5,\n",
    "    'Seaquest': 68.4,\n",
    "    'UpNDown': 533.4\n",
    "}\n",
    "\n",
    "HUMAN_SCORES = {\n",
    "    'Alien': 7127.7,\n",
    "    'Amidar': 1719.5,\n",
    "    'Assault': 742.0,\n",
    "    'Asterix': 8503.3,\n",
    "    'BankHeist': 753.1,\n",
    "    'BattleZone': 37187.5,\n",
    "    'Boxing': 12.1,\n",
    "    'Breakout': 30.5,\n",
    "    'ChopperCommand': 7387.8,\n",
    "    'CrazyClimber': 35829.4,\n",
    "    'DemonAttack': 1971.0,\n",
    "    'Freeway': 29.6,\n",
    "    'Frostbite': 4334.7,\n",
    "    'Gopher': 2412.5,\n",
    "    'Hero': 30826.4,\n",
    "    'Jamesbond': 302.8,\n",
    "    'Kangaroo': 3035.0,\n",
    "    'Krull': 2665.5,\n",
    "    'KungFuMaster': 22736.3,\n",
    "    'MsPacman': 6951.6,\n",
    "    'Pong': 14.6,\n",
    "    'PrivateEye': 69571.3,\n",
    "    'Qbert': 13455.0,\n",
    "    'RoadRunner': 7845.0,\n",
    "    'Seaquest': 42054.7,\n",
    "    'UpNDown': 11693.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d0ca97-25c1-4a76-a4d3-a5c77d2e4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helpers for loading Atari 100k data\n",
    "\n",
    "def snake_to_camel(name):\n",
    "    return ''.join(word.title() for word in name.split('_'))\n",
    "\n",
    "def convert_to_matrix(score_dict):\n",
    "    keys = sorted(list(score_dict.keys()))\n",
    "    return np.stack([score_dict[k] for k in keys], axis=1)\n",
    "  \n",
    "def load_json_scores(algorithm_name, base_path=''):\n",
    "    print(f'Loading scores for {algorithm_name}:')\n",
    "    path = osp.join(os.getcwd(), f'{algorithm_name}.json')\n",
    "    with open(path, 'r') as f:\n",
    "        scores = {}\n",
    "        for game in ATARI_100K_GAMES:\n",
    "            scores[game] = []\n",
    "            \n",
    "        results = json.load(f)['data']\n",
    "        for result in results:\n",
    "            game = snake_to_camel(result[1])\n",
    "\n",
    "            if (game == 'Median') or (game == 'Mean'):\n",
    "                continue\n",
    "            scores[game].append(result[2])\n",
    "            \n",
    "        for game, score in scores.items():\n",
    "            scores[game] = np.array(score)\n",
    "\n",
    "        scores = score_normalization(scores, RANDOM_SCORES, HUMAN_SCORES)\n",
    "        score_matrix = convert_to_matrix(scores)\n",
    "        median, mean = MEDIAN(score_matrix), MEAN(score_matrix)\n",
    "        print('{}: Median: {}, Mean: {}'.format(eval, median, mean))\n",
    "        \n",
    "    return scores, score_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45354968-502d-48a4-a1de-e42f9460be91",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1424ee3f-bf66-4c37-b2a6-948136ccc31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scores for scratch_impala:\n",
      "<built-in function eval>: Median: 0.14000109518628448, Mean: 0.179981389781448\n",
      "Loading scores for simclr_impala:\n",
      "<built-in function eval>: Median: 0.09793052461310042, Mean: 0.16336027067677328\n",
      "Loading scores for curl_impala:\n",
      "<built-in function eval>: Median: 0.15549236556950624, Mean: 0.25163054500850734\n",
      "Loading scores for byol_impala:\n",
      "<built-in function eval>: Median: 0.1475912822578321, Mean: 0.2166988775990451\n"
     ]
    }
   ],
   "source": [
    "score_dict_drq, score_drq = load_json_scores('scratch_impala')\n",
    "score_dict_simclr, score_simclr = load_json_scores('simclr_impala')\n",
    "score_dict_curl, score_curl = load_json_scores('curl_impala')\n",
    "score_dict_byol, score_byol = load_json_scores('byol_impala')\n",
    "\n",
    "score_data_dict = {'DrQ': score_drq, \n",
    "                   'SimCLR': score_simclr,\n",
    "                   'CURL': score_curl, \n",
    "                   'BYOL': score_byol}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39cd9e-2f59-4692-ad4d-2c0e91b2deea",
   "metadata": {},
   "source": [
    "### Color Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7ae7aa3-d3aa-4b34-9434-0623acf5888d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"550\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#0173b2;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#de8f05;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#029e73;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d55e00;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#cc78bc;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ca9161;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fbafe4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#949494;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ece133;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"495\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#56b4e9;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.00392156862745098, 0.45098039215686275, 0.6980392156862745),\n",
       " (0.8705882352941177, 0.5607843137254902, 0.0196078431372549),\n",
       " (0.00784313725490196, 0.6196078431372549, 0.45098039215686275),\n",
       " (0.8352941176470589, 0.3686274509803922, 0.0),\n",
       " (0.8, 0.47058823529411764, 0.7372549019607844),\n",
       " (0.792156862745098, 0.5686274509803921, 0.3803921568627451),\n",
       " (0.984313725490196, 0.6862745098039216, 0.8941176470588236),\n",
       " (0.5803921568627451, 0.5803921568627451, 0.5803921568627451),\n",
       " (0.9254901960784314, 0.8823529411764706, 0.2),\n",
       " (0.33725490196078434, 0.7058823529411765, 0.9137254901960784)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Atari_100k Color setup\n",
    "\n",
    "colors = sns.color_palette('colorblind')\n",
    "algorithms = ['DrQ','SimCLR','CURL']\n",
    "color_idxs = [0, 3, 4] #, 2, 1, 7, 8]\n",
    "ATARI_100K_COLOR_DICT = dict(zip(algorithms, [colors[idx] for idx in color_idxs]))\n",
    "atari_100k_score_dict = {key: val[:10] for key, val in score_data_dict.items()}\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01253ff4-2ff1-4c2c-9301-58a2ce2a717d",
   "metadata": {},
   "source": [
    "### Subsampling Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "391fe8b1-8abb-4ec1-a597-2589a6139c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Score helpers -- Subsampling\n",
    "\n",
    "\n",
    "def subsample_scores(score_dict, n=5, replace=False):\n",
    "    subsampled_dict = {}\n",
    "    total_samples = len(score_dict[list(score_dict.keys())[0]])\n",
    "    for game, scores in score_dict.items():\n",
    "        indices = np.random.choice(range(total_samples), size=n, replace=replace)\n",
    "        subsampled_dict[game] = scores[indices]\n",
    "    return subsampled_dict\n",
    "\n",
    "def subsample_scores_mat(score_mat, num_samples=5, replace=False):\n",
    "    subsampled_dict = []\n",
    "    total_samples, num_games = score_mat.shape\n",
    "    subsampled_scores = np.empty((num_samples, num_games))\n",
    "    for i in range(num_games):\n",
    "        indices = np.random.choice(total_samples, size=num_samples, replace=replace)\n",
    "        subsampled_scores[:, i] = score_mat[indices, i]\n",
    "    return subsampled_scores\n",
    "\n",
    "def subsample_seeds(score_mat, num_samples=5, replace=False):\n",
    "    indices = np.random.choice(\n",
    "        score_mat.shape[0], size=num_samples, replace=replace)\n",
    "    return score_mat[indices]\n",
    "\n",
    "def batch_subsample_seeds(score_mat, num_samples=5, batch_size=100,\n",
    "                          replace=False):\n",
    "    indices = [\n",
    "        np.random.choice(score_mat.shape[0], size=num_samples, replace=replace)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    return (score_mat[idx] for idx in indices)\n",
    "\n",
    "def subsample_scores_mat_with_replacement(score_mat, num_samples=5):\n",
    "    subsampled_dict = []\n",
    "    total_samples, num_games = score_mat.shape\n",
    "    indices = np.random.choice(\n",
    "      total_samples, size=(num_samples, num_games), replace=True)\n",
    "    col_indices =  np.expand_dims(np.arange(num_games), axis=0)\n",
    "    col_indices = np.repeat(col_indices, num_samples, axis=0)\n",
    "    subsampled_scores = score_mat[indices, col_indices]\n",
    "    return subsampled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e7178644-34b0-49cc-8b02-6fbcb13e8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Aggregate computation helpers\n",
    "\n",
    "SIZES = [3, 5, 10, 25, 50, 100]\n",
    "\n",
    "def calc_aggregate_fn(score_data, num_samples=5, total_n=20000, \n",
    "                      aggregate_fn=MEDIAN, replace=False):\n",
    "    subsampled_scores = batch_subsample_seeds(\n",
    "      score_data, num_samples, batch_size=total_n, replace=replace)\n",
    "    aggregates = [aggregate_fn(scores) for scores in subsampled_scores]\n",
    "    return np.array(aggregates)\n",
    "\n",
    "def calculate_aggregate_varying_sizes(score_matrix, aggregate_fn, total_n=20000,\n",
    "                                      sizes=None, replace=False):\n",
    "    agg_dict = {}\n",
    "    if sizes is None:\n",
    "        sizes = SIZES\n",
    "    for size in sizes:\n",
    "        agg_dict[n] = calc_aggregate_fn(score_matrix, num_samples=size, aggregate_fn=aggregate_fn,\n",
    "                                    total_n=total_n, replace=replace)\n",
    "        print('Mean Aggregate: {}'.format(np.mean(agg_dict[n])))\n",
    "    return agg_dict\n",
    "\n",
    "def CI(bootstrap_dist, stat_val=None, alpha=0.05, is_pivotal=False):\n",
    "    \"\"\"\n",
    "    Get the bootstrap confidence interval for a given distribution.\n",
    "    Args:\n",
    "      bootstrap_distribution: numpy array of bootstrap results.\n",
    "      stat_val: The overall statistic that this method is attempting to\n",
    "        calculate error bars for. Default is None.\n",
    "      alpha: The alpha value for the confidence intervals.\n",
    "      is_pivotal: if true, use the pivotal (reverse percentile) method. \n",
    "        If false, use the percentile method.\n",
    "    Returns:\n",
    "      (low, high): The lower and upper limit for `alpha` x 100% CIs.\n",
    "      val: The median value of the bootstrap distribution if `stat_val` is None\n",
    "        else `stat_val`.\n",
    "    \"\"\"\n",
    "    # Adapted from https://pypi.org/project/bootstrapped\n",
    "    if is_pivotal:\n",
    "        assert stat_val is not None, 'Please pass the statistic for a pivotal'\n",
    "        'confidence interval' \n",
    "        low = 2 * stat_val - np.percentile(bootstrap_dist, 100 * (1 - alpha / 2.))\n",
    "        val = stat_val\n",
    "        high = 2 * stat_val - np.percentile(bootstrap_dist, 100 * (alpha / 2.))\n",
    "    else:\n",
    "        low = np.percentile(bootstrap_dist, 100 * (alpha / 2.))\n",
    "        val = np.percentile(bootstrap_dist, 50)\n",
    "        high = np.percentile(bootstrap_dist, 100 * (1 - alpha / 2.))\n",
    "    return (low, high), val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f42fc-7dd6-45a5-8125-836ff67eb988",
   "metadata": {},
   "source": [
    "### Subsample Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "756633e1-001f-4e47-b863-2bdbccb1b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Calculating estimates for DrQ ...\n",
      "INFO:absl:Calculating estimates for CURL ...\n",
      "INFO:absl:Calculating estimates for SimCLR ...\n"
     ]
    }
   ],
   "source": [
    "#@title Aggregates on Atari 100K (with 10 runs)\n",
    "aggregate_func = lambda x: np.array([MEDIAN(x), IQM(x), MEAN(x), OG(x)])\n",
    "aggregate_scores, aggregate_interval_estimates = rly.get_interval_estimates(\n",
    "    atari_100k_score_dict, aggregate_func, reps=50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc81b4-0050-4e88-97ab-010fd8bff004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "796fd8c8-c79d-47ab-bd58-d41e54165155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DrQ': array([[0.09194846, 0.08574436, 0.15792356, 0.80536716],\n",
       "        [0.16734851, 0.11777254, 0.20232403, 0.84668908]]),\n",
       " 'CURL': array([[0.12622544, 0.12515061, 0.22837124, 0.74802136],\n",
       "        [0.17886855, 0.15261507, 0.2771191 , 0.78247336]]),\n",
       " 'SimCLR': array([[0.07029582, 0.07101171, 0.14319293, 0.83139243],\n",
       "        [0.11346079, 0.08763646, 0.18389288, 0.86485686]])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_interval_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82082fb-cc3d-486f-b6a4-009d6eb6c7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "540e1fab-69c0-4817-9f54-eb5f3db8ab98",
   "metadata": {},
   "source": [
    "### Integrate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e57f55-b694-4bfd-8b23-368f340c8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_utils.plot_interval_estimates(\n",
    "    aggregate_scores, \n",
    "    aggregate_interval_estimates,\n",
    "    metric_names = ['Median', 'IQM', 'Mean', 'Optimality Gap'],\n",
    "    algorithms=algorithms,\n",
    "    colors=ATARI_100K_COLOR_DICT,\n",
    "    xlabel_y_coordinate=-0.16,\n",
    "    xlabel='Human Normalized Score')\n",
    "plt.show()\n",
    "save_fig(fig, 'atari_100k_aggregates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c80e0-53db-4100-b481-52a03ac31a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f6e0b-4c49-4591-aa78-abcee6a6640c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a342597-3af2-4b5d-b252-f34125837a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3353508f-b670-48c4-b793-9d21576e4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"draftrec/atari_finetune\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs: \n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files \n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "          if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n",
    "\n",
    "runs_df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b94d6e-5a8e-4b6e-9522-4218169393d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
